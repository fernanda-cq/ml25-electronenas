{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion a pytorch\n",
    "En este ejercicio haremos uso de la librería de pytorch para aprendizaje profundo. Para iniciar, ve a la [página de Pytorch](https://pytorch.org/get-started/locally/) e instala la versión que corresponda a tu sistema operativo. Recuerda activar tu ambiente antes de instarlo. La instalación tomará unos minutos.\n",
    "\n",
    "```\n",
    "conda activate sistemas_inteligentes\n",
    "pip3 install torch torchvision torchaudio\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos originales\n",
    "Aquí cargamos los datos originales y observamos los valores de las primeras 3 columnas. En este ejercio utilizaremos el conjunto de datos del problema de las casas que utilizamos para entrenar regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tania\\OneDrive\\Documents\\ML\\ml25-electronenas\\src\\ml25\\E08_mlp_reg\\train.csv\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
      "0         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
      "1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
      "2         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
      "\n",
      "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
      "0       0      2    2008        WD         Normal  \n",
      "1       0      5    2007        WD         Normal  \n",
      "2       0      9    2008        WD         Normal  \n",
      "\n",
      "[3 rows x 80 columns]\n",
      "Conjunto de datos de dimensinalidad:(1460, 80), etiquetas (1460,)\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir, file):\n",
    "    path = os.path.join(data_dir, file)\n",
    "    print(os.path.abspath(path))\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "# Leer los datasets\n",
    "data_dir = \".\" \n",
    "data = read_data(data_dir, \"train.csv\")\n",
    "full_dataset, labels = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "print(full_dataset.head(3))\n",
    "print(f\"Conjunto de datos de dimensinalidad:{full_dataset.shape}, etiquetas {labels.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "Para poder simular un conjunto de prueba y evaluar nuestro modelo, separamos los datos en entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento de dimensionalidad:(1168, 80), etiquetas (1168,)\n",
      "Validación de dimensionalidad:(292, 80), etiquetas (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(full_dataset,\n",
    "                                                                  labels,\n",
    "                                                                  test_size = 0.2,\n",
    "                                                                  random_state = 0)\n",
    "print(f\"Entrenamiento de dimensionalidad:{train_data.shape}, etiquetas {train_labels.shape}\")\n",
    "print(f\"Validación de dimensionalidad:{val_data.shape}, etiquetas {val_labels.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n",
    "\n",
    "Abre el archivo .csv dentro de la carpeta de data y observa como están dados los datos. Notarás que algunas columnas tienen valores string en lugar de números, algunas filas tienen valores NaN, algunos valores están vacios y demás.\n",
    "\n",
    "La mayoría de los datasets reales son como el que usamos en este ejercicio, sin embargo para poder aprender de ellos necesitamos deshacernos de las tres condiciones anterirmente mencionadas. Por lo tanto, antes de poder aplicar cualquier método de aprendizaje primero deberémos:\n",
    "1. Eliminar cualquier celda con valores NaN\n",
    "2. Remplazar las entradas categóricas (string) por numéricas\n",
    "\n",
    "Para tratar con los NaN, vamos a asignarle un número distintivo. En este caso hemos elegido el número \"-1\". Entonces, para toda celda cuyo valor sea desconocido, simplemente le asignaremos el valor de \"-1\".\n",
    "\n",
    "Para tratar con el segundo caso, crearemos un \"mapa\" de strings a enteros. Por ejemplo si para cada casa se indica el material de construcción como \"block\" y \"ladrillo\" crearemos un mapa que nos de un número entero para cada tipo de material. Por ejemplo considera el mapeo:\n",
    "```\n",
    "material = {\"block\": 1,\n",
    "            \"ladrillo\": 2}\n",
    "```\n",
    "En este caso si en alguna fila la columna de \"material\" originalmente fuera \"block\" entonces en los datos después del pre procesamiento, ahora diría \"1\". Para ello utilizaremos la utilería de sklearn [`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html). Recuerda que es importante aplicar el mismo preprocesamiento a TODOS los datos (incluyendo los de prueba), y que los datos que utilizamos para afinar este preprocesamiento son los de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(dataset, feat_encoder, columns):\n",
    "    '''\n",
    "        args:\n",
    "        - dataset (pd.DataFrame): Conjunto de datos\n",
    "        - feat_encoder (OrdinalEncoder): instancia de codificador para las variables de entrada ajustado con datos de entrenamiento\n",
    "        returns:\n",
    "        - transformed_dataset (np.array): dataset transformado\n",
    "    '''\n",
    "    # Reemplazar valores categóricos por numéricos\n",
    "    transformed_dataset = dataset.copy()\n",
    "    transformed_dataset[columns] = feat_encoder.transform(dataset[columns])\n",
    "    # Reemplazar NaN con -1\n",
    "    transformed_dataset[np.isnan(transformed_dataset)] = -1\n",
    "    return transformed_dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento shapes (1168, 80) (1168,) <class 'numpy.ndarray'>\n",
      "Validacion shapes (292, 80) (292,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Definimos un codificador para los atributos de entrada\n",
    "# Especificamos que para valores desconocidos tome -1\n",
    "# solo usamos entrenamiento apra definir el codificador\n",
    "obj_cols = (train_data.dtypes == 'object')\n",
    "obj_cols = list(obj_cols[obj_cols].index)\n",
    "feat_encoder= OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                             unknown_value=-1)\n",
    "feat_encoder.fit(train_data[obj_cols])\n",
    "\n",
    "# Aplicamos el mismo preprocesamiento a todos los datasets\n",
    "train_data = apply_preprocessing(train_data, feat_encoder, obj_cols)\n",
    "val_data = apply_preprocessing(val_data, feat_encoder, obj_cols)\n",
    "\n",
    "# Transformar las etiquetas a arreglos de numpy\n",
    "if not isinstance(train_labels, np.ndarray):\n",
    "    train_labels = train_labels.to_numpy()\n",
    "    val_labels = val_labels.to_numpy()\n",
    "print(\"Entrenamiento shapes\", train_data.shape, train_labels.shape, type(train_data))\n",
    "print(\"Validacion shapes\", val_data.shape, val_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y aplicamos el mismo pre procesamiento a los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tania\\OneDrive\\Documents\\ML\\ml25-electronenas\\src\\ml25\\E08_mlp_reg\\test.csv\n",
      "Prueba shapes (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos de prueba y aplicamos el mismo proceso\n",
    "# Solo que en este caso no hay etiquetas\n",
    "test_data = read_data(data_dir, \"test.csv\")\n",
    "# TODO: aplica el preprocesamiento de datos al conjunto de prueba\n",
    "test_data = apply_preprocessing(test_data, feat_encoder, obj_cols)\n",
    "\n",
    "print(\"Prueba shapes\", test_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos preprocesados\n",
    "¿Recuerdas los datos originales? Después del pre procesamiento, esta es la información que recibiría el modelo durante entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos después de limpiarlos\n",
      "[[ 6.1900e+02  2.0000e+01  3.0000e+00  9.0000e+01  1.1694e+04  1.0000e+00\n",
      "  -1.0000e+00  3.0000e+00  3.0000e+00  0.0000e+00  4.0000e+00  0.0000e+00\n",
      "   1.6000e+01  2.0000e+00  2.0000e+00  0.0000e+00  2.0000e+00  9.0000e+00\n",
      "   5.0000e+00  2.0070e+03  2.0070e+03  3.0000e+00  0.0000e+00  5.0000e+00\n",
      "   5.0000e+00  1.0000e+00  4.5200e+02  0.0000e+00  4.0000e+00  2.0000e+00\n",
      "   0.0000e+00  3.0000e+00  0.0000e+00  2.0000e+00  4.8000e+01  5.0000e+00\n",
      "   0.0000e+00  1.7740e+03  1.8220e+03  1.0000e+00  0.0000e+00  1.0000e+00\n",
      "   4.0000e+00  1.8280e+03  0.0000e+00  0.0000e+00  1.8280e+03  0.0000e+00\n",
      "   0.0000e+00  2.0000e+00  0.0000e+00  3.0000e+00  1.0000e+00  2.0000e+00\n",
      "   9.0000e+00  5.0000e+00  1.0000e+00  2.0000e+00  1.0000e+00  2.0070e+03\n",
      "   2.0000e+00  3.0000e+00  7.7400e+02  4.0000e+00  4.0000e+00  2.0000e+00\n",
      "   0.0000e+00  1.0800e+02  0.0000e+00  0.0000e+00  2.6000e+02  0.0000e+00\n",
      "  -1.0000e+00 -1.0000e+00 -1.0000e+00  0.0000e+00  7.0000e+00  2.0070e+03\n",
      "   6.0000e+00  5.0000e+00]\n",
      " [ 8.7100e+02  2.0000e+01  3.0000e+00  6.0000e+01  6.6000e+03  1.0000e+00\n",
      "  -1.0000e+00  3.0000e+00  3.0000e+00  0.0000e+00  4.0000e+00  0.0000e+00\n",
      "   1.2000e+01  4.0000e+00  2.0000e+00  0.0000e+00  2.0000e+00  5.0000e+00\n",
      "   5.0000e+00  1.9620e+03  1.9620e+03  3.0000e+00  0.0000e+00  8.0000e+00\n",
      "   8.0000e+00 -1.0000e+00  0.0000e+00  3.0000e+00  4.0000e+00  1.0000e+00\n",
      "   3.0000e+00  3.0000e+00  3.0000e+00  5.0000e+00  0.0000e+00  5.0000e+00\n",
      "   0.0000e+00  8.9400e+02  8.9400e+02  1.0000e+00  2.0000e+00  0.0000e+00\n",
      "   4.0000e+00  8.9400e+02  0.0000e+00  0.0000e+00  8.9400e+02  0.0000e+00\n",
      "   0.0000e+00  1.0000e+00  0.0000e+00  2.0000e+00  1.0000e+00  3.0000e+00\n",
      "   5.0000e+00  5.0000e+00  0.0000e+00 -1.0000e+00  5.0000e+00  1.9620e+03\n",
      "   2.0000e+00  1.0000e+00  3.0800e+02  4.0000e+00  4.0000e+00  2.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  -1.0000e+00 -1.0000e+00 -1.0000e+00  0.0000e+00  8.0000e+00  2.0090e+03\n",
      "   8.0000e+00  4.0000e+00]\n",
      " [ 9.3000e+01  3.0000e+01  3.0000e+00  8.0000e+01  1.3360e+04  1.0000e+00\n",
      "   0.0000e+00  0.0000e+00  1.0000e+00  0.0000e+00  4.0000e+00  0.0000e+00\n",
      "   6.0000e+00  2.0000e+00  2.0000e+00  0.0000e+00  2.0000e+00  5.0000e+00\n",
      "   7.0000e+00  1.9210e+03  2.0060e+03  1.0000e+00  0.0000e+00  1.3000e+01\n",
      "   1.4000e+01 -1.0000e+00  0.0000e+00  3.0000e+00  2.0000e+00  0.0000e+00\n",
      "   2.0000e+00  3.0000e+00  3.0000e+00  0.0000e+00  7.1300e+02  5.0000e+00\n",
      "   0.0000e+00  1.6300e+02  8.7600e+02  1.0000e+00  0.0000e+00  1.0000e+00\n",
      "   4.0000e+00  9.6400e+02  0.0000e+00  0.0000e+00  9.6400e+02  1.0000e+00\n",
      "   0.0000e+00  1.0000e+00  0.0000e+00  2.0000e+00  1.0000e+00  3.0000e+00\n",
      "   5.0000e+00  5.0000e+00  0.0000e+00 -1.0000e+00  5.0000e+00  1.9210e+03\n",
      "   2.0000e+00  2.0000e+00  4.3200e+02  4.0000e+00  4.0000e+00  2.0000e+00\n",
      "   0.0000e+00  0.0000e+00  4.4000e+01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  -1.0000e+00 -1.0000e+00 -1.0000e+00  0.0000e+00  8.0000e+00  2.0090e+03\n",
      "   8.0000e+00  4.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos después de limpiarlos\")\n",
    "print(train_data[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir un dataloader\n",
    "\n",
    "Después de haber limpiado los datos, definiremos un dataloader para poder iterarlos. Esta es una clase proprietaria de pytorch donde podemos aplicar distintas técnicas de regularización y preprocesamiento al dataset según se requiera. También nos permitirá definir cómo queremos recibir los datos durante el entrenamiento. Puedes leer mas sobre los dataloaders en el siguiente enlace: [dataloaders en pytorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168 292\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "class HousingDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data.astype('float32')\n",
    "        self.labels = labels.astype('float32')\n",
    "\n",
    "        # TODO: calcula la cantidad de variables de entrada y salida\n",
    "        self.input_dims = data.shape[1] #N,D\n",
    "        self.output_dims = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.data.shape, type(self.data), idx)\n",
    "        # print(self.labels.shape, type(self.labels), idx)\n",
    "        datapoint = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        label = np.expand_dims(label,0) # Transformarlo a vector de 1x1\n",
    "        return datapoint, label\n",
    "\n",
    "# DATASETS\n",
    "train_dataset = HousingDataset(train_data, train_labels)\n",
    "val_dataset = HousingDataset(val_data, val_labels)\n",
    "total_train_data, total_val_data = len(train_dataset), len(val_dataset)\n",
    "\n",
    "print(total_train_data, total_val_data)\n",
    "print(val_dataset.input_dims)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder aplicar descenso de gradiente estocástico necesitamos poder seleccionar distintos indices de nuestro conjunto de datos. Esto está automatizado por pytorch y nosotros podemos indicarle de qué tamaño será el batch size y si queremos que seleccione los indices aleatoriamente o no.\n",
    "\n",
    "En la celda anterior nosotros definimos nuestro conjunto de datos de las casas (HousingDataset) donde dado un indice i, regresamos un tuple (dato[i], label[i]).\n",
    "\n",
    "En la siguiente celda definimos nuestros dataloaders donde especificamos el batch size a utilizar y probamos como funciona. Intenta cambiar el batch size y observa cuantas iteraciones hace el dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En ENTRENAMIENTO hay 1168 datos. Hicimos 9 iteraciones con un batch_size de 128\n",
      "En VALIDACIÓN hay 292 datos. Hicimos 2 iteraciones con un batch_size de 128\n"
     ]
    }
   ],
   "source": [
    "# TODO: Cambia el batch size y responde la pregunta de la celda siguiente\n",
    "batch_size = 128\n",
    "\n",
    "# DATALOADERS\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "# Iteraciones\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "print(f\"En ENTRENAMIENTO hay {len(train_dataset)} datos. Hicimos {i} iteraciones con un batch_size de {batch_size}\")\n",
    "\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "print(f\"En VALIDACIÓN hay {len(val_dataset)} datos. Hicimos {i} iteraciones con un batch_size de {batch_size}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Responde\n",
    "¿Como se relaciona la cantidad de iteraciones, la cantidad de datos en el dataset y el batch_size?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir la red neuronal\n",
    "Ahora vamos a definir la red neuronal (: Aquí mostraremos dos formas de hacerlo. La primera consiste en utilizar la clase sequential y la segunda es hacerlo \"manualmente\". La ventaja de la última, es que tienes más control sobre como defines tu red. \n",
    "Investiga como declarar una red neuronal en pytorch usando la clase [sequential]([https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
    "\n",
    "Otras clases importantes son las funciones de activación: [non-linear Activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "y las capas completamente conectadas: [linear layers](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definiendo red con 80 variables de entradas y 1 variables de salida\n"
     ]
    }
   ],
   "source": [
    "# Tenemos \n",
    "input_dims = train_dataset.input_dims\n",
    "output_dims = train_dataset.output_dims\n",
    "print(f\"Definiendo red con {input_dims} variables de entradas y {output_dims} variables de salida\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opción A)\n",
    "Declarando la red con nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Agrega más capas a la siguiente red.\n",
    "# Puedes utilizar funciones de activación ReLU para las capas escondidas\n",
    "# Definiendo la red con sequential\n",
    "import torch.nn  as nn\n",
    "net1 = nn.Sequential(\n",
    "        nn.Linear(80, 256),   # capa lineal entran ..., salen ... features\n",
    "        nn.ReLU(),             # activación ReLu a la lineal anterior\n",
    "        nn.Linear(256, 128),   # capa lineal entran ... salen ... features\n",
    "        nn.ReLU(), \n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),   # capa lineal entran ... salen ... features\n",
    "        nn.Linear(64, 1),\n",
    "        \n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opción B)\n",
    "Declarando la red \"manualmente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Agrega más capas a la siguiente red y modifca el forward pass de acuerdo a tus adiciones\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__()\n",
    "        # TODO: Define las capas así como la cantidad de variables de entrada y salida\n",
    "        self.fc1 = nn.Linear(80, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Define el forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        ...\n",
    "        return x\n",
    "net2 = Net(input_dims, output_dims)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia / forward pass\n",
    "\n",
    "En este momento tenemos una red no entrenada, sin embargo ya podemos usarla para inferencia. Vamos a intentar propagar algunos datos de entrenamiento y observemos las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagando matriz de datos de dimensionalidad torch.Size([128, 80]), con etiquetas de dimensionalidad torch.Size([128, 1])\n",
      "Costo de red 1: 37534048256.0\n",
      "Costo de red 2: 37530603520.0\n"
     ]
    }
   ],
   "source": [
    "X, y_hat = next(iter(train_loader))\n",
    "print(f\"Propagando matriz de datos de dimensionalidad {X.shape}, con etiquetas de dimensionalidad {y_hat.shape}\")\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# ==== Red 1 ==== #\n",
    "# Forward pass de red 1\n",
    "pred_net1 = net1.forward(X)\n",
    "\n",
    "# Calculando el costo\n",
    "cost1 = loss(pred_net1, y_hat)  # Pred, target\n",
    "print(f\"Costo de red 1: {cost1}\")\n",
    "\n",
    "# ==== Red 2 ==== #\n",
    "# Forward pass de red 2\n",
    "pred_net2 = net2(X)\n",
    "\n",
    "# Calculando el costo\n",
    "cost2 = loss(pred_net2, y_hat)  # Pred, target\n",
    "print(f\"Costo de red 2: {cost2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando el pipeline\n",
    "Ya estamos casi listos para entrenar! pero antes... define la función validation_step.\n",
    "\n",
    "Durante entrenamiento, al final de cada epoch predeciremos el **costo total** del conjunto de datos de validación. Esto nos permitirá determinar si la actualización de los pesos está convergiendo a un valor deseado, y en base a ello modificar los hiperparámetros de ser necesario. Esta función deberá:\n",
    "- calcular las predicciones de un minibatch\n",
    "- calcular el costo del minibatch\n",
    "- sumar los costos para regresar el costo promedio por minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo TOTAL de validación antes de entrenar: 43396102826.666664\n"
     ]
    }
   ],
   "source": [
    "def validation_step(val_loader, net, cost_function):\n",
    "    '''\n",
    "        Realiza un epoch completo en el conjunto de validación\n",
    "        args:\n",
    "        - val_loader (torch.DataLoader): dataloader para los datos de validación\n",
    "        - net: definición de la red neuronal (con nn.Sequential o la clase anteriormente definida)\n",
    "        - cost_function(torch.nn): Función de costo a utilizar\n",
    "\n",
    "        returns:\n",
    "        - val_loss (float): el costo total (promedio por minibatch) de todos los datos de validación\n",
    "    '''\n",
    "    val_loss = 0.0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Este decorador de \"torch.inference_mode()\" solo se utiliza DURANTE INFERENCIA\n",
    "        # ya que lo que hace es evitar que se puedan actualizar los parámetros de la red.\n",
    "        # Por lo tanto es importante solo usarlo en inferencia (es decir, evítalo en entrenamiento)\n",
    "        with torch.inference_mode():\n",
    "            # TODO: Calcula las predicciones de \"inputs\"\n",
    "            preds = net(inputs)\n",
    "            # TODO: Calcula el costo\n",
    "            loss = cost_function(preds,labels)\n",
    "\n",
    "            # Sumamos los costos para calcular el promedio\n",
    "            val_loss += loss.item()\n",
    "    return val_loss/len(val_loader)\n",
    "\n",
    "# Probando el validation_step\n",
    "loss = nn.MSELoss()\n",
    "costo_validacion = validation_step(val_loader, net1, loss)\n",
    "print(f\"Costo TOTAL de validación antes de entrenar: {costo_validacion}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas de entrenamiento\n",
    "Para poder visualizar el entrenamiento de la red en tiempo real, primero definimos una clase de utiliería. Ejecuta la celda y procede a la siguiente sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses():\n",
    "    def __init__(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, train_loss, val_loss):        \n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.i += 1\n",
    "        plt.plot(self.x, self.losses, label=\"Costo de entrenamiento promedio\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"Costo de validación promedio\")\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos en clase, para entrenar la red es necesario antes definir los hiperparámetros. Estos incluyen:\n",
    "- Los epochs\n",
    "- El ritmo de aprendizaje (learning_rate)\n",
    "- El batch_size\n",
    "- La cantidad de capas\n",
    "- La cantidad de neuronas por capa\n",
    "\n",
    "Existen muchos otros hiperparámetros para obtener mejor generalización, sin embargo por ahora nos enfocaremos en estos.\n",
    "En la siguiente celda puedes modificar los hiperparámetros de entrenamiento. Recuerda siempre correr esta celda antes de entrenar la red para que se reflejen los nuevos hiperparámetros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# TODO: Modifica los hiperparámetros y prueba entrenar con ellos hasta que encuentres una configuración adecuada\n",
    "# Hiperparametros\n",
    "config = {\n",
    "    \"n_epochs\": 75,\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 24,\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=config['batch_size'],\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=config['batch_size'],\n",
    "                        shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si! estamos listos para entrenar tu primera red neuronal. En esta celda aplicarás descenso de gradiente estocástico al dataset del problema de las casas, utilizando TODAS las variables de entrada. Para ellos deberás:\n",
    "- Definir la función de costo\n",
    "- Hacer el forward pass\n",
    "- Calcular el costo del minibatch\n",
    "- Calcular el gradiente del minibatch\n",
    "- Actualizar los pesos con el gradiente anterior\n",
    "\n",
    "y repetir los pasos anteriores por una cantidad de epochs determinada.\n",
    "\n",
    "Una vez finalizado todo corre el entrenamiento y visualiza como cambia el loss según se entrena la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAGwCAYAAAC5ACFFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPBRJREFUeJzt3QmcjfX////X2Ca77Maa7Aplpz4qRCmKsmRLIoVsCRGl+o+SD/lY2/gQ2ZJPRXZJyJZkJx/Z9zVhTOb9u73e3/91PueMM2+DWczM4367HTPnuq5zbec413Pe79d1XSHGGCMAAAAIKlXwwQAAACAsAQAAXActSwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4JDGNRKxExUVJYcPH5bMmTNLSEgIuw0AgCRALzX5559/SlhYmKRKFXP7EWEpDmhQKliwYFzMCgAAJLADBw5IgQIFYhxPWIoD2qLk7ewsWbLExSwBAEA8O3/+vG3s8I7jMSEsxQGv602DEmEJAICk5XolNBR4AwAAOBCWAAAAHAhLAAAADtQsAUgwV69elcjISPY4gASRNm1aSZ069S3Ph7AEIEGuZXL06FE5e/YsextAgsqWLZvkzZv3lq6DSFgCEO+8oJQ7d27JkCEDF28FkCB/pF28eFGOHz9un+fLl++m50VYAhDvXW9eUMqRIwd7G0CCSZ8+vf2pgUm/g262S44CbwDxyqtR0hYlAEho3nfPrdRLEpYAJAjumwggqX73EJYAAAAcCEsAAAAOhCUASMbdD3PmzEns1Ug2nn/+eXnqqacSezWStR9++MF+br3LjEycONGe+p/YCEsA4LjkQdeuXaVo0aISGhpq707+5JNPypIlS+Jkn90uB4L4llxC20cffWTfs7j01ltvSYUKFeJ0nslJs2bNZNeuXYm9Glw6AACC+eOPP6RmzZo2zAwdOlTuvfdeezbNggULpHPnzrJjxw52XBy6cuWKpEuX7rbep1mzZpXkdh0ivbRHmjRpbutT/9P//6f/JyZalgAk/IXirvydKA9ddmy98sortkVk7dq10qRJEylRooSULVtWevbsKT///LNvuv3790ujRo0kU6ZMkiVLFmnatKkcO3bMN37Tpk3y8MMPS+bMme34ihUryvr16213Q7t27eTcuXN2OfrQVgZ15swZadOmjdx55532tOfHHntMdu/e7VxfHf+Pf/xD7rjjDilTpowsWrTommkOHDhg108DYPbs2e16ayh02bJli12+bl+ePHmkdevWcvLkSd/4hx56SF599VV5/fXX7Tz1SsnedqgiRYrYn08//bTdRu+516Ly6aefyl133WXXW2n3y4svvii5cuWy++uRRx6x+9DjvW7y5Ml2XhpgmjdvLn/++advmvnz58sDDzxgt1Ov7fXEE0/Inj17fON1m3VdZsyYIQ8++KA9GFeuXNm2YKxbt04qVapkt1e3+8SJEzF2w0VFRUl4eLhdf51H+fLlZdasWdd0KWlLpM5T38saNWrIzp077XhtpXr77bft9nmfAa/l6nqfq+i8bZo2bZpdhu7Pe+65R5YvX37N+nz//ff2c6itpT/99JNERETY91CvQ6Sv032n+yH66xYsWCD33Xef3VZ9X/TaRTqv0qVL23V87rnn7EUgY7t/1Lx58+z/LR2v/0+ifx6Dtb6OHTtW7r77bhuuS5YsaT8L8e32jZMAkqVLkVelzMAFibLsbYPrSYZ01//aO336tD3gvvfee5IxY8Zrxntf3now8A5oelD6+++/bauTdh3oAUa1bNnSHmD0C14viPfrr7/a+1XpAW3EiBEycOBA38FT5+MdlDX8fPPNN/Yg1KdPH3n88cdl27Zt9rXR6Xo0btzYhpk1a9bYANa9e/eAabRVrF69elK9enVZsWKFbU149913pX79+vLbb78FbdXR4KIHRQ0vw4cPl0uXLtl10QP30qVLfdP9+9//tiFSl7169Wq7/toqV7duXXvQ1YPwhAkT7LL8Lwr4+++/y1dffSWzZ8/2DX/22WftgVMPwhqExo8fL7Vr17ZBRsOY0uCj3XrfffedDZa6PkOGDLHvl/rrr7/s+pQrV04uXLhg97GGNd33qVL9r41g0KBB9j0oVKiQvPDCC/Zgr6FWu9s02Oh89bX63gWjQeCLL76QcePGSfHixeXHH3+UVq1a2aBXq1Yt33T9+/eXYcOG2eGdOnWyy1q5cqX9nGgY1c/a4sWL7bS6zbH5XMWkd+/edps0MP/zn/+03cZ79+4NuCBs37595cMPP7TdyxrINejq+6DvY+HCheWDDz6wnxV9f7x97gXVUaNG+faNPjRwTZ061e5n3cf/+te/7GckNvtHw7t+bnXbOnbsaP+I6NWrl7h8/fXX0q1bN7uNderUsZ8B/aOjQIECNmzFG4Nbdu7cOf1z1f4EEOjSpUtm27Zt9qf6KyLSFO7zXaI8dNmxsWbNGvt/evbs2c7pFi5caFKnTm3279/vG7Z161b72rVr19rnmTNnNhMnTgz6+gkTJpisWbMGDNu1a5d9/cqVK33DTp48adKnT29mzJgRdD4LFiwwadKkMYcOHfIN+/777+18vv76a/t88uTJpmTJkiYqKso3TUREhJ2vvj6Yd955xzz66KMBww4cOGDnu3PnTvu8Vq1a5oEHHgiYpnLlyqZPnz6+5/7r4Rk0aJBJmzatOX78uG/YihUrTJYsWczly5cDpr377rvN+PHjfa/LkCGDOX/+vG987969TdWqVU1MTpw4Yddh8+bN9vnevXvt808//dQ3zZdffmmHLVmyxDcsPDzc7jNP27ZtTaNGjezvuo66HqtWrQpYVvv27U2LFi3s78uWLbPzXLx4sW/83Llz7TDv/4NuT/ny5W/4cxWdt01DhgzxDYuMjDQFChQw77//fsD6zJkzxzfNhQsX7PswZcoU37ArV66YsLAw88EHH8S4HeHh4XbYnj17fMNeeuklU69evVjvn379+pkyZcoEjNfPjc73zJkzQf+P1KhRw3To0CHgNc8++6x5/PHHTWy/g27m+E3LEoAElT5tatvCk1jLjo3Ydtdt377dFn3rw6N/0WvLk47Trh1t4dCWGe0q0L+EteVEuxBc89RWn6pVq/qGaauAdjfoONd6hIWF+YZpC5I/7erRlgJtOfF3+fLlgC6q6K9ZtmyZr8XLn75Gu0+UtuD403tweffjctFWDG1l8F+etlBEvy2Otmj5r6N2v/lvR/TlaauctghpS5d2GWpLjde1pV1THv/11lY5pbVp/sNi2g7dl9rlpK1n0WuvtCXRn/9yvPuT6Xy1RetmP1cx8X/f9XOk3X/RPzc6zKP7VVsdtSXQo62XVapUueZ15aLtL21h0tYp/2HabR3b/aPz9/+cR1//mPaNtkL503XX1sD4RFgCkKC09iFDLLrCEpN2Geh6xkURt3ZdaPfO3LlzbdeSdv1oXYl2WSQkDSFapzJlypRrxvkHluiv0W6c999//5px/jcljd41qPvOCygu0bs4dXk632BdTf51K9dbnq6zBrFPPvnEBkgdpyFJD9T+/OfjXeU5+rCYtkPXVen7mj9//oBx2jV1veXEZv/El2Bdy7GRNtp2uN6HG9k/SQEF3gAQjdZpaM3G6NGjbf1LdN41YLSwVesu9OHRuiIdry0BHm2B6dGjhyxcuNDWaGj9jtI6IT0byZ/OU2tUtFXEc+rUKVvX5D/P6K/RdThy5IhvmH8Rurr//vtti4vWDxUrVizgEdNZXvqarVu32pac6K+5kQOuHlSjb2dMy9PLNWiLSPTl5cyZM1bL8vbVgAEDbK2T7huta4pr+l7oQV9bq6Kvq3+L0PXE9BmIzecqGP/3XT9HGzZssPOLiVcorTVUHm1p0lqz6y3rVvePrpfXEhXT5zY6fY3/uip9fivrGhuEJQAIQoOSHsS0O0KLXzVoaBfAyJEjfV0F2q2m3TZaxP3LL7/YL349i02LV7WrQ7uPunTpYltK9u3bZ7/U9SDkHbw0hOhf4Hq2lHYXabeFtmppcW+HDh3smUraNaVFsfrXuQ4PRtdDA1nbtm3t9FrArUXF/nQdNXDoPHS8Fv3qeulZUAcPHgw6Xy281WL3Fi1a2PXWLhs9I0oLamMTfjy6nbqNGoRcwUW3Q/etnnGmwVLPjFq1apXdFi3+jQ0tWNZuvI8//th2BWkhunaFxjXtBnzttddsCNbCaN03+hnQAmd9fiP7Rt8LLT7Xz4CemXa9z9X1PrdaBK2tovr+6f7WgvKYaOh9+eWXbWG4FpprKNPPnn4W27dvL/G5fzp16mT/X+myNeBqofj1rmOl0+o0WnSvr9Uidj1BQJcVr5wVTYgVCrwBc1PFlbe7w4cPm86dO5vChQubdOnSmfz585uGDRvaglfPvn377LCMGTPaYm4tNj169KivgLp58+amYMGC9vVaNNulS5eAfdGpUyeTI0cOW2Sqxb7q9OnTpnXr1rawVQuwtWhWC79dtOBaC611OSVKlDDz58+/prD6yJEjpk2bNiZnzpwmNDTUFC1a1BbLuopbdblPP/20yZYtm12XUqVKme7du/sKxbXAu1u3bgGv0SJoLYb2fPPNN6ZYsWK2CF33ZUyFzUoLt7t27Wr3lRYe675r2bKlr9g52OuGDx/um69atGiRKV26tN3GcuXKmR9++CFgX3jF0Bs3bvS9xiti9gqLgxUX+xd4K90HI0aMsEXguq65cuWy79Xy5ctjnKcuU4fpOniF0E2aNLH7V4frMq/3uQrG26apU6eaKlWq2M+BFk8vXbrUuY1KP4+6z73PRc2aNQMKyZfFYt8Ee2+ut3/Ut99+az8butwHH3zQfP75584CbzVmzBj72dV56md90qRJMe6XuCrwDtF/4jeOJX/nz5+3zdh6uq6e5gsgsIBY/3L2v5YOgLilrXD6f2zjxo1cEfwGvoNie/ymGw4AAMCBsAQAAOBwe5+/CwAAYlUoTlVN/KFlCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAIAUS88g01tmxPZ2KkiZCEsAkEzpXeDnzJmTqOug9/HKli2b7/lbb7113StMP//88/b+cHHFtczw8HB7T7Ty5cvH2fKS+pXA9XOj96pTev/AkJAQ382jUyrCEgDEQG/82rVrVylatKi9g7reLf3JJ5+0N4WNjyCREugNT+Nq/93qMn/88UeZNWuWfaRNmzZB1ympqFGjhhw5csTeEiQl46KUABDDX9g1a9a0YWbo0KH2LvCRkZGyYMECezd3vas7blymTJns43ZY5j/+8Q/55ZdfJDHpZ+p2Dmrp0qWTvHnzSkpHyxKAhKX37r7yV+I8buC+4a+88ortfli7dq00adJESpQoIWXLlpWePXvKzz//7Jtu//790qhRI3sw1htxNm3aVI4dO+Ybv2nTJnn44Yclc+bMdnzFihVtfYx2b7Rr187ewFOXow/tLlJnzpyRNm3ayJ133ikZMmSQxx57THbv3u1cXx2vB3+9UWiZMmVk0aJF10xz4MABu34aALNnz27XW0NhMFFRUVKgQAEZO3ZswHC9UWuqVKlk37599rnW+2iQzJgxo2150/124cKFWHeJXb161e5TXaccOXLI66+/fs2VqLWb7IEHHvBN88QTT8iePXsCpjl48KC0aNHCbpeuS6VKlWTNmjVBl6nbNnjwYLt92mKo43QZ0buiZs+ebd87fQ+0m2716tXioq/R/aXvV/r06W2LpLZaRZ/v9OnTpVatWva9mjJlSqzXZ8aMGfLggw/aeVeuXFl27dol69ats9uqnz9d7okTJwLW6dNPP5XSpUvbZZUqVUrGjBkTMF4/3/fdd58dr/PR99dfsG64r776yv5f0HXVK4cPGzZMkjtalgAkrMiLIv9fWOLs9TcOi6TLeN3JTp8+bQ9W7733nj3wRud1nelBzgtKy5cvl7///tu2OjVr1sweZFTLli3twUgPoqlTp7a1INqSoN0bI0aMkIEDB8rOnTvttF7rh9bsaPj55ptvbMDq06ePPP7447Jt27agrRC6Ho0bN5Y8efLYgKABrHv37te0YNSrV0+qV68uK1askDRp0si7774r9evXl99++822IPjTQKThY+rUqfLyyy/7huvBXVvcChcu7Jtu5MiR9o7u//3vf21Y0sAT/aAcEz3Qanfk559/bg/q+vzrr7+WRx55xDfNX3/9ZQNVuXLlbBDTffb000/bfanL12EaPvLnz2/3mbaEaIuR7pdgPvroI7uc8ePH2/dGl92wYUPZunWrFC9e3Ddd//795cMPP7TD9HfdH7///rvddzF58803ZciQIXYZkydPlubNm8vmzZvttnn69u1rl++FlNiuz6BBg+xnplChQvLCCy/Ic889Z0O4vl4DnQZh3TdewNX3Sp+PGjXKzleDUIcOHexnum3btna/afCsW7eufPHFF7J3717p1q2b8/3asGGDXY4GUP2cr1q1yr7nGmL1c5tsGdyyc+fO6Z9B9ieAQJcuXTLbtm2zP62IC8YMypI4D112LKxZs8b+n549e7ZzuoULF5rUqVOb/fv3+4Zt3brVvnbt2rX2eebMmc3EiRODvn7ChAkma9asAcN27dplX79y5UrfsJMnT5r06dObGTNmBJ3PggULTJo0acyhQ4d8w77//ns7n6+//to+nzx5silZsqSJioryTRMREWHnq68PZuPGjSYkJMTs27fPPr969arJnz+/GTt2bIz7ZObMmSZHjhwxbuOgQYNM+fLlfc/z5ctnPvjgA9/zyMhIU6BAAdOoUaMYl3HixAm7bZs3b7bPx48fb/fzqVOngk4ffZlhYWHmvffeC5imcuXK5pVXXrG/7927187/008/veZ93b59e4zrpeM7deoUMKxq1arm5ZdfDpjviBEjAqa5mfX58ssv7bAlS5b4hoWHh9v32HP33XebqVOnBsz3nXfeMdWrV/ftN32vfP83jbHvrc5X33u1bNky+/zMmTP2+XPPPWfq1q0bMM/evXubMmXKmCTzHXQTx29algAkrLQZ/q+FJ7GWHQuxvSHp9u3bbdeTPjzaBaYtTzpOu0q0ReTFF1+0rQx16tSRZ599Vu6++27nPLXlomrVqr5h+ld7yZIl7TjXeoSF/a/FTluQ/Gl3oLaKaEuEv8uXL1/TpeXR7iBtEdHWJW0N0daz48eP223wLF682J5RpjVc58+ft61rOs+LFy/a1g4XbQHT4mH/bdVt1+4g//dAW9m0hURbzU6ePOlrMdIu0Hvuuce2MGnLiXbBXY+u4+HDh23rmD99rvvIn7ZkefLly2d/6vZrd1ZMou93fe6dWebR7bvV9dFWRKVdoP7DdP281jh9X9u3b29bkzz6/njF2vq50Xlq61ZM6x/d9u3bbWtq9HXVFi/tUtXW0+SIsAQgYYWExKorLDFp14fWacRFEbd2V2h3ydy5c+X777+3XSnTpk2z3UgJSbtctF5Ku2aiy5UrV4yv025ELyzpT+220/Dm1dJoN45202mXpYaVn376yR6gr1y5ct2wFFt6BqJ2+33yySc2EGpY0pCky1BawxMf/Ls89fOgYurauxHBunZvdn2iD/PWz6sb033mH0ZVcg008YkCbwCIRg/6Wt8zevRo+xd6dF6xq7a6aNG0PjxaV6TjtYXJo8XhPXr0kIULF9raogkTJtjhWiekf43703nqX/9ecbI6deqUrWvyn2f01+g6aCuNx78IXd1///22hSZ37txSrFixgIfrtHANelu2bLG1KlqsrOHJo8P04Kz1NtWqVbPbqa0ksaXL1RYb/23Vbdf5Rt/2AQMGSO3ate22agG8P20d0dYbrTW7Hq0B08C1cuXKgOH6PKb9eyOi73d97l+vlFDro61MOl+tI4v+fmt9mdL10no1bQmMaf2jK126dNB11fc+WYeweOwmTDGoWQJurl7gdrZnzx6TN29eW4sxa9YsW0uk2/HRRx+ZUqVK2Wm0/qdChQrmwQcfNBs2bLC1ThUrVjS1atWy4y9evGg6d+5s6z7++OMP89NPP9k6ktdff92O17ok/RpevHixrcP566+/7HCt19Hlrlixwvz666+mfv36plixYubKlStB11VriXR6rSXR6X/88Ue7Hv41Szrv4sWLm4ceesiO/+9//2vXq2vXrubAgQPOfVGzZk1b86N1QbpNHl2WV4Oj+2vSpEm2psm/xuV6NUtDhgwx2bNnt+up9UAdOnSwy/FqlnTbtK6mVatWZvfu3bZGR+t5/LdNa69KlChh3wfdx7ou+p6tWrUq6DKHDx9usmTJYqZNm2Z27Nhh+vTpY9KmTWvfY/8aIa9uR+n26DDdZzHR8Tlz5jSfffaZ2blzpxk4cKBJlSqVrXeKab43uz7Ra4mC7etPPvnE1qTpZ1bX57fffjOff/65GTZsmB3/559/2vXVfavrOHfuXPs5c9UsbdiwwW7T4MGD7Ty1Hk+XoctOzjVLhKU4QFgCkl9YUocPH7Zhp3DhwiZdunQ2CDRs2DDggKnFzzosY8aM9iD/7LPPmqNHj/oO4s2bNzcFCxa0r9dC3i5dugTsCy0I1jCgX9h6UFenT582rVu3tgc+PRDVq1fPd+CMiR64HnjgAbscDQ7z588PCBTqyJEjpk2bNvYAGRoaaooWLWrDyfUOFGPGjLHz0tdG989//tMWaXvrqYHpRsKSFnR369bNhoVs2bKZnj172uX4F3gvWrTIlC5d2q5zuXLlzA8//HDNtmkYbdKkiZ1PhgwZTKVKlWx4DbZMDWBvvfWWfT81lOg4LYj33EpYGj16tA2tuq5FihQx06dPd873ZtcnNmFJTZkyxQZ6/Vzceeed5h//+EfAiQurV6+2y9PxOt1XX33lDEtKg6iGc13XQoUKmaFDh5rbWVyEpRD9J7Fbt5I6LdDT5mQtVtQmVQD/o038ekqyNv37F5ICyY3WDOllD+LyVi2I3++g2B6/k1zNktYQ6EWwdIO1aE0vqOUyc+ZMe+aCTq9nDcybNy/GaTt16mQ/7FrVDwAAkOTCkl71VE/D1bNJ9IJjekVVLcL0TpWMTi+WpRcR0zMz9GJcmvb1ocWK0elfA1rY5n/qLQAAQJIKS3pZfb1ehN4iQM8SGDdunD01Va92Goxe1VRPc+3du7et4H/nnXfsGSF6NVN/hw4dsjfL1FNqb+d79AAAbl9a1UIXXPKUZMKSXk9DTyfVi7p59DL3+jym+/XocP/plbZE+U+vp722bt3aBiq9101sRERE2H5O/wcAAEiekkxY0qu26vVIvKuWevT50aNHg75Gh19v+vfff99eMfbVV1+N9bro1Wq1IMx7+F+9F0BwnEsCIKl+9ySZsBQftKVKu+r0Jo7e1VBjo1+/frZy3nv4X5AOQCCva1tvfwEACc377rmVMpskc7uTnDlz2quDHjt2LGC4Ptc7TAejw13T6523tThc7+Ds0darXr162TPi9FL+wYSGhtoHgOvT/7d6rzTvRAytM7yRP04A4GZblDQo6XePfgfdyhXGk0xY0tsC6H2NlixZ4iug03ojfd6lS5egr9EbAur47t27+4YtWrTId6NArVUKVtOkw7WIHEDc8P5AienMVQCILxqUYmpUSXZhSellA9q2bWvv2FylShXb+qP3bfKCTZs2bSR//vy2pkh169ZNatWqZe9b1KBBA3vzyvXr18vHH39sx+vNIL0bQnq0mU53qt7hG0Dc0JYkvQeY3pcsMjKS3QogQegxPS7uWZekwlKzZs3kxIkTMnDgQFukXaFCBZk/f76viHv//v32DDlPjRo17F2y9QaMb7zxhr2T+Jw5c+zdqgEkPP3SStY32wSQLHG7kzjA7U4AAEh6ku3tTgAAABISYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAgOQUlkaPHi1FihSRO+64Q6pWrSpr1651Tj9z5kwpVaqUnf7ee++VefPm+cZFRkZKnz597PCMGTNKWFiYtGnTRg4fPpwAWwIAAJKCJBWWpk+fLj179pRBgwbJL7/8IuXLl5d69erJ8ePHg06/atUqadGihbRv3142btwoTz31lH1s2bLFjr948aKdz5tvvml/zp49W3bu3CkNGzZM4C0DAAC3qxBjjJEkQluSKleuLKNGjbLPo6KipGDBgtK1a1fp27fvNdM3a9ZM/vrrL/nuu+98w6pVqyYVKlSQcePGBV3GunXrpEqVKrJv3z4pVKhQrNbr/PnzkjVrVjl37pxkyZLlprcPAAAknNgev5NMy9KVK1dkw4YNUqdOHd+wVKlS2eerV68O+hod7j+90paomKZXusNCQkIkW7ZsMU4TERFhd7D/AwAAJE9JJiydPHlSrl69Knny5AkYrs+PHj0a9DU6/Eamv3z5sq1h0q47V8IMDw+3SdR7aOsWAABInpJMWIpvWuzdtGlT0V7JsWPHOqft16+fbYHyHgcOHEiw9QQAAAkrjSQROXPmlNSpU8uxY8cChuvzvHnzBn2NDo/N9F5Q0jqlpUuXXrfuKDQ01D4AAEDyl2RaltKlSycVK1aUJUuW+IZpgbc+r169etDX6HD/6dWiRYsCpveC0u7du2Xx4sWSI0eOeNwKAACQ1CSZliWllw1o27atVKpUyZ6xNmLECHu2W7t27ex4vUZS/vz5bU2R6tatm9SqVUuGDRsmDRo0kGnTpsn69evl448/9gWlZ555xl42QM+Y05oor54pe/bsNqABAICULUmFJb0UwIkTJ2TgwIE21OglAObPn+8r4t6/f789Q85To0YNmTp1qgwYMEDeeOMNKV68uMyZM0fuueceO/7QoUPyzTff2N91Xv6WLVsmDz30UIJuHwAAuP0kqess3a64zhIAAElPsrvOEgAAQGIgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAIjrsHTgwAE5ePCg7/natWule/fu8vHHH9/M7AAAAJJXWHruuedk2bJl9vejR49K3bp1bWDq37+/DB48OK7XEQAAIGmFpS1btkiVKlXs7zNmzJB77rlHVq1aJVOmTJGJEyfG9ToCAAAkrbAUGRkpoaGh9vfFixdLw4YN7e+lSpWSI0eOxO0aAgAAJLWwVLZsWRk3bpysWLFCFi1aJPXr17fDDx8+LDly5IjrdQQAAEhaYen999+X8ePHy0MPPSQtWrSQ8uXL2+HffPONr3sOAAAgOQgxxpibeeHVq1fl/Pnzcuedd/qG/fHHH5IhQwbJnTu3pCS6H7JmzSrnzp2TLFmyJPbqAACAODx+31TL0qVLlyQiIsIXlPbt2ycjRoyQnTt3xntQGj16tBQpUkTuuOMOqVq1qj0Lz2XmzJm2lkqnv/fee2XevHkB4zUrDhw4UPLlyyfp06eXOnXqyO7du+N1GwAAQNJxU2GpUaNGMmnSJPv72bNnbWgZNmyYPPXUUzJ27FiJL9OnT5eePXvKoEGD5JdffrHdf/Xq1ZPjx48HnV7P0NNuwvbt28vGjRvt+ulDz+bzfPDBBzJy5Ehbg7VmzRrJmDGjnefly5fjbTsAAEASYm5Cjhw5zJYtW+zvn3zyiSlXrpy5evWqmTFjhilVqpSJL1WqVDGdO3f2PddlhoWFmfDw8KDTN23a1DRo0CBgWNWqVc1LL71kf4+KijJ58+Y1Q4cO9Y0/e/asCQ0NNV9++WWs1+vcuXPalWl/AgCApCG2x++balm6ePGiZM6c2f6+cOFCady4saRKlUqqVatmu+Tiw5UrV2TDhg22m8yjy9Tnq1evDvoaHe4/vdJWI2/6vXv32otq+k+jfZfaUhbTPJV2QWo/p/8DAAAkTzcVlooVKyZz5syxtz1ZsGCBPProo3a4dofFV4HzyZMnbVF5njx5Aobrcw08wehw1/TezxuZpwoPD7ehynsULFjwprcLAAAkw7CkBdGvvfaaLbTWSwVUr17d18p03333SXLXr18/WznvPTQ0AgCA5CnNzbzomWeekQceeMBerdu7xpKqXbu2PP300xIfcubMKalTp5Zjx44FDNfnefPmDfoaHe6a3vupw/RsOP9pKlSoEOO66NXLvSuYAwCA5O2mWpa8oKGtSHrV7oMHD9ph2sqkp+nHh3Tp0knFihVlyZIlvmFRUVH2udeyFZ0O959e6RXHvenvuusuux3+02j9kZ4VF9M8AQBAynJTYUlDyuDBg229TuHChe0jW7Zs8s4779hx8UUvG/DJJ5/Iv//9b9m+fbu8/PLL8tdff0m7du3s+DZt2tguMk+3bt1k/vz59rIGO3bskLfeekvWr18vXbp0seNDQkKke/fu8u6779qrj2/evNnOIywszF5iAAAA4Ka64fr37y+fffaZDBkyRGrWrGmH/fTTTzaM6PWJ3nvvvXjZs82aNZMTJ07YmiktwNauMg1DXoH2/v377Rlynho1asjUqVNlwIAB8sYbb0jx4sVtYfo999zjm+b111+3gatjx472mlHavajz1ItYAgAA3NTtTrTlRS/i2LBhw4Dh//nPf+SVV16RQ4cOpag9y+1OAABIeuL1dienT58OWpukw3QcAABAcnFTYUnPgBs1atQ1w3VYuXLl4mK9AAAAkm7Nkt5PrUGDBrJ48WLfWWN6xWu93lD0G9UCAACkuJalWrVqya5du+w1lbQoWh96y5OtW7fK5MmT434tAQAAklKBd0w2bdok999/v70tSUpCgTcAAElPvBZ4AwAApBSEJQAAAAfCEgAAQFydDadF3C5a6A0AAJBiw5IWQV1vvN5bDQAAIEWGpQkTJsTfmgAAANyGqFkCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAgLAEAABwc2hZAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAABAcghLp0+flpYtW0qWLFkkW7Zs0r59e7lw4YLzNZcvX5bOnTtLjhw5JFOmTNKkSRM5duyYb/ymTZukRYsWUrBgQUmfPr2ULl1aPvroowTYGgAAkFQkmbCkQWnr1q2yaNEi+e677+THH3+Ujh07Ol/To0cP+fbbb2XmzJmyfPlyOXz4sDRu3Ng3fsOGDZI7d2754osv7Lz79+8v/fr1k1GjRiXAFgEAgKQgxBhj5Da3fft2KVOmjKxbt04qVapkh82fP18ef/xxOXjwoISFhV3zmnPnzkmuXLlk6tSp8swzz9hhO3bssK1Hq1evlmrVqgVdlrZE6fKWLl0a4/pERETYh+f8+fO2dUqXqS1fAADg9qfH76xZs173+J0kWpY03GjXmxeUVJ06dSRVqlSyZs2aoK/RVqPIyEg7nadUqVJSqFAhO7+Y6A7Lnj27c33Cw8PtzvUeGpQAAEDylCTC0tGjR213mb80adLYUKPjYnpNunTpbMjylydPnhhfs2rVKpk+ffp1u/e0q05Dlfc4cODADW8TAABIGhI1LPXt21dCQkKcD+06SwhbtmyRRo0ayaBBg+TRRx91ThsaGmqb6/wfAAAgeUqTmAvv1auXPP/8885pihYtKnnz5pXjx48HDP/777/tGXI6LhgdfuXKFTl79mxA65KeDRf9Ndu2bZPatWvbFqUBAwbc0jYBAIDkJVHDkhZg6+N6qlevbkOP1iFVrFjRDtMC7KioKKlatWrQ1+h0adOmlSVLlthLBqidO3fK/v377fw8ehbcI488Im3btpX33nsvzrYNAAAkD0nibDj12GOP2VahcePG2cLtdu3a2YJvPdtNHTp0yLYOTZo0SapUqWKHvfzyyzJv3jyZOHGi7Srr2rWrrzbJ63rToFSvXj0ZOnSob1mpU6eOVYi70Wp6AABw+4jt8TtRW5ZuxJQpU6RLly42EOlZcNpaNHLkSN94DVDacnTx4kXfsOHDh/um1VP9NRSNGTPGN37WrFly4sQJe50lfXgKFy4sf/zxRwJuHQAAuF0lmZal2xktSwAAJD3J6jpLAAAAiYWwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAABAWAIAALg5tCwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAABAcghLp0+flpYtW0qWLFkkW7Zs0r59e7lw4YLzNZcvX5bOnTtLjhw5JFOmTNKkSRM5duxY0GlPnTolBQoUkJCQEDl79mw8bQUAAEhqkkxY0qC0detWWbRokXz33Xfy448/SseOHZ2v6dGjh3z77bcyc+ZMWb58uRw+fFgaN24cdFoNX+XKlYuntQcAAElViDHGyG1u+/btUqZMGVm3bp1UqlTJDps/f748/vjjcvDgQQkLC7vmNefOnZNcuXLJ1KlT5ZlnnrHDduzYIaVLl5bVq1dLtWrVfNOOHTtWpk+fLgMHDpTatWvLmTNnbOtVTCIiIuzDc/78eSlYsKBdprZ8AQCA258ev7NmzXrd43eSaFnScKPhxQtKqk6dOpIqVSpZs2ZN0Nds2LBBIiMj7XSeUqVKSaFChez8PNu2bZPBgwfLpEmT7PxiIzw83O5c76FBCQAAJE9JIiwdPXpUcufOHTAsTZo0kj17djsuptekS5fumhaiPHny+F6jrUMtWrSQoUOH2hAVW/369bMp1HscOHDgprYLAADc/hI1LPXt29cWVLse2nUWXzT0aLdcq1atbuh1oaGhtrnO/wEAAJKnNIm58F69esnzzz/vnKZo0aKSN29eOX78eMDwv//+254hp+OC0eFXrlyxZ7b5ty7p2XDea5YuXSqbN2+WWbNm2ede+VbOnDmlf//+8vbbb9/yNgIAgKQtUcOSFmDr43qqV69uQ4/WIVWsWNEXdKKioqRq1apBX6PTpU2bVpYsWWIvGaB27twp+/fvt/NTX331lVy6dMn3Gi0gf+GFF2TFihVy9913x9FWAgCApCxRw1JsaVdZ/fr1pUOHDjJu3DhbuN2lSxdp3ry570y4Q4cO2TPZtFC7SpUqtvBaLwfQs2dPW9ukXWVdu3a1Qck7Ey56IDp58qRvea6z4QAAQMqRJMKSmjJlig1IGoj0rDVtLRo5cqRvvAYobTm6ePGib9jw4cN902oxd7169WTMmDGJtAUAACApShLXWUou12kAAAC3j2R1nSUAAIDEQlgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAADgQFgCAABwICwBAAA4EJYAAAAcCEsAAAAOhCUAAAAHwhIAAIADYQkAAMCBsAQAAOBAWAIAAHAgLAEAADgQlgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcEjjGonYMcbYn+fPn2eXAQCQRHjHbe84HhPCUhz4888/7c+CBQvGxewAAEACH8ezZs0a4/gQc704heuKioqSw4cPS+bMmSUkJERSekrX0HjgwAHJkiVLYq9OssV+Zl8nN3ym2c+JQSOQBqWwsDBJlSrmyiRaluKA7uACBQrExaySDQ1KhCX2c3LCZ5r9nJzwef4fV4uShwJvAAAAB8ISAACAA2EJcSo0NFQGDRpkfyL+sJ8TDvua/Zyc8Hm+ORR4AwAAONCyBAAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLuGGnT5+Wli1b2ouaZcuWTdq3by8XLlxwvuby5cvSuXNnyZEjh2TKlEmaNGkix44dCzrtqVOn7EU+9WroZ8+eTbHvUHzs502bNkmLFi3sVdbTp08vpUuXlo8++khSktGjR0uRIkXkjjvukKpVq8ratWud08+cOVNKlSplp7/33ntl3rx511wBeODAgZIvXz67T+vUqSO7d++WlC4u93NkZKT06dPHDs+YMaO92nKbNm3snRNSurj+PPvr1KmT/R4eMWJEPKx5EqO3OwFuRP369U358uXNzz//bFasWGGKFStmWrRo4XxNp06dTMGCBc2SJUvM+vXrTbVq1UyNGjWCTtuoUSPz2GOP6W14zJkzZ1LsmxMf+/mzzz4zr776qvnhhx/Mnj17zOTJk0369OnNv/71L5MSTJs2zaRLl858/vnnZuvWraZDhw4mW7Zs5tixY0GnX7lypUmdOrX54IMPzLZt28yAAQNM2rRpzebNm33TDBkyxGTNmtXMmTPHbNq0yTRs2NDcdddd5tKlSyaliuv9fPbsWVOnTh0zffp0s2PHDrN69WpTpUoVU7FiRZOSxcfn2TN79mz7/RMWFmaGDx9uUjrCEm6I/gfTELNu3TrfsO+//96EhISYQ4cOBX2NftHpf8iZM2f6hm3fvt3OR7/0/I0ZM8bUqlXLHuxTcliK7/3s75VXXjEPP/ywSQn0ANu5c2ff86tXr9qDQXh4eNDpmzZtaho0aBAwrGrVquall16yv0dFRZm8efOaoUOHBrwPoaGh5ssvvzQpVVzv52DWrl1rP9v79u0zKVV87eeDBw+a/Pnzmy1btpjChQsTlowxdMPhhqxevdp2CVWqVMk3TLsd9P54a9asCfqaDRs22GZ0nc6jzcCFChWy8/Ns27ZNBg8eLJMmTXLe0DAliM/9HN25c+cke/bsktxduXLF7iP//aP7U5/HtH90uP/0ql69er7p9+7dK0ePHg2YRu8zpd0hrn2enMXHfo7pc6tdRPr/JCWKr/2sN4Zv3bq19O7dW8qWLRuPW5C0pOwjEm6YHhhy584dMCxNmjT2YKvjYnpNunTprvlSy5Mnj+81ERERtpZm6NCh9uCe0sXXfo5u1apVMn36dOnYsaMkdydPnpSrV6/a/RHb/aPDXdN7P29knsldfOznYLV5WsOk3xkp9Ybd8bWf33//fftd8+qrr8bTmidNhCVYffv2tX+luR47duyIt73Vr18/W2zcqlWrZP2OJPZ+9rdlyxZp1KiRvT3No48+miDLBG6Vtp42bdrUFtaPHTuWHRqHtKVKT/iYOHGi/S7C/6Tx+x0pWK9eveT55593TlO0aFHJmzevHD9+PGD433//bc/c0nHB6HBtMtYz2/xbPfQsLe81S5culc2bN8usWbPsc/0iVDlz5pT+/fvL22+/LclBYu9n/y7P2rVr2xalAQMGSEqgn6XUqVNfcxZmsP3j0eGu6b2fOkzPhvOfpkKFCpISxcd+jh6U9u3bZ78zUmqrUnzt5xUrVtjvHf/WfW296tWrlz0j7o8//pAUK37KzpDcC4/1TCvPggULYlV4PGvWLN8wPaPFv/D4999/t2dkeA89u0PHr1q1KsYzO5Kz+NrPSos2c+fObXr37m1SYkFsly5dAgpitZDVVRD7xBNPBAyrXr36NQXeH374oW/8uXPnKPCO4/2srly5Yp566ilTtmxZc/z48Rt+75OjuN7PJ0+eDPge1ocWjPfp08d+l6RkhCXc1Cnt9913n1mzZo356aefTPHixQNOadczKUqWLGnH+5/SXqhQIbN06VIbAPQ/qD5ismzZshR9Nlx87Wf98suVK5dp1aqVOXLkiO+RUg4+eqq1nqk2ceJEG0g7duxoT7U+evSoHd+6dWvTt2/fgFOt06RJY8OQnlk4aNCgoJcO0Hn85z//Mb/99pu99AWXDojb/axBSS/JUKBAAfPrr78GfHYjIiJMShUfn+foOBvu/xCWcMNOnTplD9qZMmUyWbJkMe3atTN//vmnb/zevXtt0NHA49Frzugp6nfeeafJkCGDefrpp+0XXUwIS/Gzn/XLUV8T/aFfiCmFXlNKA6Ven0b/MtfrWHn0shVt27YNmH7GjBmmRIkSdnpt1Zg7d27AeG1devPNN02ePHnsgat27dpm586dJqWLy/3sfdaDPfw//ylRXH+eoyMs/Z8Q/SexuwIBAABuV5wNBwAA4EBYAgAAcCAsAQAAOBCWAAAAHAhLAAAADoQlAAAAB8ISAACAA2EJAADAgbAEAHHghx9+sHdq1xsZA0heCEsAAAAOhCUAAAAHwhKAZCEqKkrCw8PlrrvukvTp00v58uVl1qxZAV1kc+fOlXLlyskdd9wh1apVky1btgTM46uvvpKyZctKaGioFClSRIYNGxYwPiIiQvr06SMFCxa00xQrVkw+++yzgGk2bNgglSpVkgwZMkiNGjVk586dvnGbNm2Shx9+WDJnzixZsmSRihUryvr16+N1vwC4dYQlAMmCBqVJkybJuHHjZOvWrdKjRw9p1aqVLF++3DdN7969bQBat26d5MqVS5588kmJjIz0hZymTZtK8+bNZfPmzfLWW2/Jm2++KRMnTvS9vk2bNvLll1/KyJEjZfv27TJ+/HjJlClTwHr079/fLkNDUJo0aeSFF17wjWvZsqUUKFDALl+X17dvX0mbNm2C7B8At8AAQBJ3+fJlkyFDBrNq1aqA4e3btzctWrQwy5YtM/p1N23aNN+4U6dOmfTp05vp06fb588995ypW7duwOt79+5typQpY3/fuXOnnceiRYuCroO3jMWLF/uGzZ071w67dOmSfZ45c2YzceLEONxyAAmBliUASd7vv/8uFy9elLp169qWHu+hLU179uzxTVe9enXf79mzZ5eSJUvaFiKlP2vWrBkwX32+e/duuXr1qvz666+SOnVqqVWrlnNdtJvPky9fPvvz+PHj9mfPnj3lxRdflDp16siQIUMC1g3A7YuwBCDJu3Dhgv2pNUkaarzHtm3bfHVLt0rroGLDv1tN66S8eiqlXXvaRdigQQNZunSplClTRr7++us4WT8A8YewBCDJ09ChBdf79++3Rdf+Dy3G9vz888++38+cOSO7du2S0qVL2+f6c+XKlQHz1eclSpSwLUr33nuvDT3+NVA3Q+en9VQLFy6Uxo0by4QJE25pfgDiX5oEWAYAxCs9u+y1116zIUQDzQMPPCDnzp2zYUfPOitcuLCdbvDgwZIjRw7JkyePLcTOmTOnPPXUU3Zcr169pHLlyvLOO+9Is2bNZPXq1TJq1CgZM2aMHa9nx7Vt29YWbGuBt55tt2/fPtvFpoXh13Pp0iVbYP7MM8/YM/YOHjxoC72bNGnCpwO43SVIZRQAxLOoqCgzYsQIU7JkSZM2bVqTK1cuU69ePbN8+XJf8fW3335rypYta9KlS2eqVKliNm3aFDCPWbNm2YJufX2hQoXM0KFDA8ZroXaPHj1Mvnz57DyKFStmPv/8czvOW8aZM2d802/cuNEO27t3r4mIiDDNmzc3BQsWtK8NCwszXbp08RV/A7h9heg/iR3YACA+6XWW9PpG2vWWLVs2djaAG0LNEgAAgANhCQAAwIFuOAAAAAdalgAAABwISwAAAA6EJQAAAAfCEgAAgANhCQAAwIGwBAAA4EBYAgAAcCAsAQAASMz+H629ClWncDLmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "# TODO: Elige la red que quieres utilizar. Tambien recuerda que puedes modificarla a tu gusto\n",
    "input_dims = train_dataset.input_dims\n",
    "output_dims = train_dataset.output_dims\n",
    "net = net2\n",
    "\n",
    "# TODO: Define la función de costo a utilizar\n",
    "cost_function = nn.MSELoss()\n",
    "\n",
    "# Mandamos los parametros de la red para que los pueda optimizar\n",
    "optimizer = optim.Adam(net.parameters(),\n",
    "                       lr=config['lr'])\n",
    "\n",
    "loss_plot = PlotLosses()\n",
    "for epoch in range(config['n_epochs']):  # loop over the dataset multiple times\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Realiza el forward pass/ las predicciones actuales para los datos \"inputs\"\n",
    "        y_hat=net(inputs)\n",
    "        # TODO: Calcula el costo para las predicciones y las etiquetas(labels)\n",
    "        loss=cost_function(y_hat,labels)\n",
    "        # TODO: Calcula los gradientes para todos los parámetros\n",
    "        loss.backward()\n",
    "        # TODO: Actualiza los pesos\n",
    "        optimizer.step()\n",
    "        # Sumamos el costo del minibatch para calcular el promedio\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Calculamos el costo promedio\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print(train_loss)\n",
    "    \n",
    "    # Por cada \n",
    "    val_loss = validation_step(val_loader, net, cost_function)\n",
    "\n",
    "    # Actualizamos la gráfica de las curvas de entrenamiento\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    time.sleep(0.5)\n",
    "    loss_plot.on_epoch_end(epoch, train_loss, val_loss)\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de prueba (Inferencia)\n",
    "Ahora que la red está entrenada, vamos a predecir los valores para el conjunto de prueba. La siguiente celda utiliza la red que has entrenado anteriormente, calcula las predicciones y genera un csv con las mismas. \n",
    "\n",
    "Vamos a ver que equipo logra el menor costo! Ya que tengas las predicciones del conjunto de prueba, súbelas a la [siguiente competencia de Kaggle](https://www.kaggle.com/t/5c4905135a7a4742899e2064b1bb0ce4) para que veas el leaderboard.\n",
    "\n",
    "En esta competencia podrán participar los dos grupos y los equipos ganadores recibirán puntos extra en el examen (:\n",
    "Puedes subir tus predicciones más de una vez.\n",
    "\n",
    "Si te interesa encontrar maneras de mejorar la predicción de tu red, puedes consultar la documentación de pytorch sobre [Optimizadores](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "Puedes intentar, investigar sobre los parámetros adicionales de [Descenso de gradiente Estocástico (SGD)](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) o usar un optimizador distinto como [ADAM](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html?highlight=adam#torch.optim.Adam), [ADAGRAD](https://pytorch.org/docs/stable/generated/torch.optim.Adagrad.html#torch.optim.Adagrad) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tania\\OneDrive\\Documents\\ML\\ml25-electronenas\\src\\ml25\\E08_mlp_reg\\test.csv\n",
      "Prueba shapes (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos de prueba y aplicamos el mismo proceso\n",
    "# Solo que en este caso no hay etiquetas\n",
    "test_data = read_data(data_dir, \"test.csv\")\n",
    "\n",
    "ids = np.array(test_data['Id'], dtype=int)\n",
    "test_data = apply_preprocessing(test_data, feat_encoder, obj_cols)\n",
    "print(\"Prueba shapes\", test_data.shape)\n",
    "\n",
    "test_data = torch.tensor(test_data, dtype=torch.float)\n",
    "with torch.inference_mode():\n",
    "    preds = net(test_data)\n",
    "\n",
    "preds = preds.detach().cpu().numpy()\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": ids,\n",
    "    \"SalePrice\": preds.squeeze()\n",
    "})\n",
    "submission_df.to_csv(\"test_preds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
